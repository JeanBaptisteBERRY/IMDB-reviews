{
 "metadata": {
  "name": "",
  "signature": "sha256:db8904089b5efa01f9962419b99126c24b94d030f0b15c6dd92b713cc777a2db"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext watermark\n",
      "\n",
      "%watermark -a 'Vahid Mirjalili' -d -p scikit-learn,numpy,numexpr,pandas,matplotlib,plotly -v"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Vahid Mirjalili 20/12/2014 \n",
        "\n",
        "CPython 2.7.3\n",
        "IPython 2.3.1\n",
        "\n",
        "scikit-learn 0.15.2\n",
        "numpy 1.9.1\n",
        "numexpr 2.2.2\n",
        "pandas 0.15.1\n",
        "matplotlib 1.4.2\n",
        "plotly 1.4.7\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib import pyplot as plt\n",
      "%matplotlib inline\n",
      "\n",
      "import numpy as np\n",
      "import scipy\n",
      "\n",
      "import logging\n",
      "import numpy as np\n",
      "\n",
      "from sklearn.datasets import fetch_20newsgroups\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "from sklearn import metrics"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Loading the Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')\n",
      "\n",
      "categories = None \n",
      "\n",
      "remove = ('headers', 'footers', 'quotes')\n",
      "\n",
      "data_train = fetch_20newsgroups(subset='train', categories=categories,\n",
      "                                shuffle=True, random_state=42,\n",
      "                                remove=remove)\n",
      "\n",
      "data_test = fetch_20newsgroups(subset='test', categories=categories,\n",
      "                               shuffle=True, random_state=42,\n",
      "                               remove=remove)\n",
      "\n",
      "categories = data_train.target_names\n",
      "\n",
      "print(\"Categories: %s\" %categories)\n",
      "\n",
      "y_train, y_test = data_train.target, data_test.target\n",
      "\n",
      "print(\"Dataset size: Training: %d Testing: %d\" % (y_train.shape[0], y_test.shape[0]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Categories: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
        "Dataset size: Training: 11314 Testing: 7532\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Vectorization (TF-IDF)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "TF-IDF stands for Term frequency inverse document frequency, is a statistical measure to see how important the appearance of a word in a document corpus is for classification. **Term frequency** measures how many times a term has appeared in a particular document, and **inverse document frequency** measures logarithm inverse of number of ducuments that have that word out of total number of documents. **Augmented TF-IDF** is used to avoid bias towards longer documents, and it is defined as below for a term $t$ appearing in a particular document $d$:\n",
      "\n",
      "$$ TF(t, d) = 0.5 + \\frac{0.5 \\times freq(t, d)}{max(freq(w, d) \\ \\ where\\  w \\in d)} $$\n",
      "\n",
      "$$IDF(t, D_{train}) = \\frac{|D_{train}|}{|\\{d\\in D_{train} \\ \\ where\\  t \\in d\\}|}$$\n",
      "\n",
      "and \n",
      "\n",
      "$$TFIDF(t, d, D) = TF(t,d) \\times IDF(t, d)$$\n",
      "\n",
      "where $D_{train}=\\{set\\ of\\ all\\ training\\ documents\\}$. It is important to note that **TF-IDF** depends on the entire set of documents that we are considering (for example the training set), and not just the term in a document."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Vectorizing the training set:\n",
      "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
      "                             stop_words='english')\n",
      "X_train = vectorizer.fit_transform(data_train.data)\n",
      "\n",
      "print(\"Number of samples N= %d,  Number of features d= %d\" % X_train.shape)\n",
      "\n",
      "\n",
      "### Transforming the test dataset:\n",
      "X_test = vectorizer.transform(data_test.data)\n",
      "\n",
      "print(\"Number of Test Documents: %d,  Number of features: %d\" %X_test.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of samples N= 11314,  Number of features d= 101323\n",
        "Number of Test Documents: 7532,  Number of features: 101323"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## A Generic Classifier Function"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Train the classifier and test:\n",
      "def do_classify(clf):\n",
      "    clf.fit(X_train, y_train)\n",
      "    pred = clf.predict(X_test)\n",
      "\n",
      "    score = metrics.f1_score(y_test, pred)\n",
      "\n",
      "    return(score)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}