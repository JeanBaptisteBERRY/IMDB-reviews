{
 "metadata": {
  "name": "",
  "signature": "sha256:d8bc85c25c5ea3c38bd12f00be5e25c9874741f62af8ad30db8bf2f1247c5678"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext watermark\n",
      "\n",
      "%watermark -a 'Vahid Mirjalili' -d -p scikit-learn,numpy,numexpr,pandas,matplotlib,plotly -v"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Vahid Mirjalili 25/12/2014 \n",
        "\n",
        "CPython 2.7.3\n",
        "IPython 2.3.1\n",
        "\n",
        "scikit-learn 0.15.2\n",
        "numpy 1.9.1\n",
        "numexpr 2.2.2\n",
        "pandas 0.15.1\n",
        "matplotlib 1.4.2\n",
        "plotly 1.4.7\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib import pyplot as plt\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import scipy\n",
      "import sklearn\n",
      "\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/PIL/Image.py:71: RuntimeWarning: The _imaging extension was built for another  version of Pillow or PIL\n",
        "  warnings.warn(str(v), RuntimeWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/PIL/Image.py:71: RuntimeWarning: The _imaging extension was built for another  version of Pillow or PIL\n",
        "  warnings.warn(str(v), RuntimeWarning)\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 1. Read the training and test dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_table('../data/labeledTrainData.tsv')\n",
      "\n",
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>id</th>\n",
        "      <th>sentiment</th>\n",
        "      <th>review</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 5814_8</td>\n",
        "      <td> 1</td>\n",
        "      <td> With all this stuff going down at the moment w...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 2381_9</td>\n",
        "      <td> 1</td>\n",
        "      <td> \\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 7759_3</td>\n",
        "      <td> 0</td>\n",
        "      <td> The film starts with a manager (Nicholas Bell)...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 3630_4</td>\n",
        "      <td> 0</td>\n",
        "      <td> It must be assumed that those who praised this...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 9495_8</td>\n",
        "      <td> 1</td>\n",
        "      <td> Superbly trashy and wondrously unpretentious 8...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "       id  sentiment                                             review\n",
        "0  5814_8          1  With all this stuff going down at the moment w...\n",
        "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
        "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
        "3  3630_4          0  It must be assumed that those who praised this...\n",
        "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_test = pd.read_table('../data/testData.tsv')\n",
      "\n",
      "df_test.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>id</th>\n",
        "      <th>review</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 12311_10</td>\n",
        "      <td> Naturally in a film who's main themes are of m...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>   8348_2</td>\n",
        "      <td> This movie is a disaster within a disaster fil...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>   5828_4</td>\n",
        "      <td> All in all, this is a movie for kids. We saw i...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>   7186_2</td>\n",
        "      <td> Afraid of the Dark left me with the impression...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>  12128_7</td>\n",
        "      <td> A very accurate depiction of small time mob li...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "         id                                             review\n",
        "0  12311_10  Naturally in a film who's main themes are of m...\n",
        "1    8348_2  This movie is a disaster within a disaster fil...\n",
        "2    5828_4  All in all, this is a movie for kids. We saw i...\n",
        "3    7186_2  Afraid of the Dark left me with the impression...\n",
        "4   12128_7  A very accurate depiction of small time mob li..."
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 1.1 Extracting X & y data columns"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_train = df.loc[:, 'review']\n",
      "\n",
      "y_train = df.loc[:, 'sentiment']\n",
      "\n",
      "data_train.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "0    With all this stuff going down at the moment w...\n",
        "1    \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
        "2    The film starts with a manager (Nicholas Bell)...\n",
        "3    It must be assumed that those who praised this...\n",
        "4    Superbly trashy and wondrously unpretentious 8...\n",
        "Name: review, dtype: object"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_test = df_test.loc[:, 'review']\n",
      "\n",
      "data_test.tail()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "24995    Sony Pictures Classics, I'm looking at you! So...\n",
        "24996    I always felt that Ms. Merkerson had never got...\n",
        "24997    I was so disappointed in this movie. I am very...\n",
        "24998    From the opening sequence, filled with black a...\n",
        "24999    This is a great horror film for people who don...\n",
        "Name: review, dtype: object"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2. Text Feature Extraction"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "import string\n",
      "import re\n",
      "from collections import Counter\n",
      "\n",
      "from nltk.corpus import stopwords"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/PIL/Image.py:71: RuntimeWarning: The _imaging extension was built for another  version of Pillow or PIL\n",
        "  warnings.warn(str(v), RuntimeWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/PIL/Image.py:71: RuntimeWarning: The _imaging extension was built for another  version of Pillow or PIL\n",
        "  warnings.warn(str(v), RuntimeWarning)\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 2.1 Tokenizer Function"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      " **Transform to lower-case**  \n",
      " **Remove the punctuations**  \n",
      " **Remove the stopwrods**  \n",
      " **Tokenize the remaining string**  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## For more info, see http://www.cs.duke.edu/courses/spring14/compsci290/assignments/lab02.html\n",
      "\n",
      "stemmer = nltk.stem.porter.PorterStemmer()\n",
      "\n",
      "def get_tokens(inp_txt):\n",
      "    \n",
      "    ## Lower case: ABC -> abc\n",
      "    txt_lower = inp_txt.lower()\n",
      "  \n",
      "    ## Remove punctuations (!, ', \", ., :, ;, )\n",
      "    #txt_lower_nopunct = txt_lower.translate(string.maketrans(\"\",\"\"), string.punctuation)\n",
      "    #print(txt_lower_nopunct)\n",
      "    \n",
      "    \n",
      "    ## Tokenize:\n",
      "    tokens = nltk.word_tokenize(txt_lower) #_nopunct)\n",
      "    #tokens = nltk.wordpunct_tokenize(txt_lower)\n",
      "    \n",
      "    ## remove stop-words:\n",
      "    tokens_filtered = [w for w in tokens if not w in stopwords.words('english')]\n",
      "    \n",
      "    ## stemming:\n",
      "    stems = [stemmer.stem(t) for t in tokens_filtered]\n",
      "    stems_nopunct = [s for s in stems if re.match('^[a-zA-Z]+$', s) is not None]\n",
      "    return (stems_nopunct)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Unit test for tokenizer:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_tokens(\"What's in a name? That which we call a rose by any other name would smell as sweet.\")\n",
      "\n",
      "## Note: you need to download punkt package in nltk:\n",
      "# import nltk\n",
      "# nltk.download(punkt)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "[u'name', u'call', u'rose', u'name', u'would', u'smell', u'sweet']"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 2.2 TF-IDF Feature Extraction"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfidf = sklearn.feature_extraction.text.TfidfVectorizer(\n",
      "    encoding = 'utf-8',\n",
      "    decode_error = 'replace',\n",
      "    strip_accents = 'ascii',\n",
      "    analyzer = 'word',\n",
      "    smooth_idf = True,\n",
      "    tokenizer = get_tokens\n",
      ")\n",
      "\n",
      "tfidf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "TfidfVectorizer(analyzer='word', binary=False, charset=None,\n",
        "        charset_error=None, decode_error='replace',\n",
        "        dtype=<type 'numpy.int64'>, encoding='utf-8', input=u'content',\n",
        "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
        "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
        "        stop_words=None, strip_accents='ascii', sublinear_tf=False,\n",
        "        token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
        "        tokenizer=<function get_tokens at 0xb31bed8>, use_idf=True,\n",
        "        vocabulary=None)"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Unit test for TF-IDF:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Shakespear quote\n",
      "example_txt_1 = \"What's in a name? That which we call a rose by any other name would smell as sweet.\"\n",
      "example_txt_2 = \"To be, or not to be: that is the question.\"\n",
      "\n",
      "tfidf = tfidf.fit([example_txt_1 + example_txt_2])\n",
      "\n",
      "example1 = tfidf.transform([example_txt_1])\n",
      "example2 = tfidf.transform([example_txt_2])\n",
      "\n",
      "print('Features: %s' %tfidf.get_feature_names())\n",
      "print('Example1: %s' %example1.toarray())\n",
      "print('Example2: %s' %example2.toarray())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Features: [u'call', u'name', u'question', u'rose', u'smell', u'would']\n",
        "Example1: [[ 0.35355339  0.70710678  0.          0.35355339  0.35355339  0.35355339]]\n",
        "Example2: [[ 0.  0.  1.  0.  0.  0.]]\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 2.3 Evaluate TF-IDF on the reviews"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Vectorizing the training set:\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "\n",
      "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
      "                             stop_words='english')\n",
      "X_train = vectorizer.fit_transform(data_train)\n",
      "\n",
      "print(\"Number of samples N= %d,  Number of features d= %d\" % X_train.shape)\n",
      "\n",
      "\n",
      "### Transforming the test dataset:\n",
      "X_test = vectorizer.transform(data_test)\n",
      "\n",
      "print(\"Number of Test Documents: %d,  Number of features: %d\" %X_test.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of samples N= 25000,  Number of features d= 74536\n",
        "Number of Test Documents: 25000,  Number of features: 74536"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 3. Setup Grid Search Cross Validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import pipeline\n",
      "from sklearn import metrics\n",
      "from sklearn import grid_search\n",
      "from sklearn import cross_validation\n",
      "from sklearn.naive_bayes import MultinomialNB"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alpha_params = [0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1.0, 2.0]\n",
      "alpha_params = [0.01, 0.02]\n",
      "colors = [\"red\", \"green\"] #, \"blue\", \"\"]\n",
      "pointtypes = ['o', '^']\n",
      "\n",
      "fig_roc = plt.figure(1, figsize=(10, 8))\n",
      "ax_roc = fig_roc.add_subplot(1, 1, 1)\n",
      "\n",
      "for param,col,ptype in zip(alpha_params, colors, pointtypes):\n",
      "    clf_pipe = pipeline.Pipeline([\n",
      "        ('vect', tfidf),\n",
      "        ('clf', MultinomialNB(alpha=param))\n",
      "    ])\n",
      "\n",
      "    cv = cross_validation.StratifiedKFold(y_train[1:100], n_folds=5)\n",
      "    \n",
      "    auc_res = 0\n",
      "    xr = np.linspace(0, 1, 100)\n",
      "    tpr_interp = np.zeros(shape=xr.shape, dtype=float)\n",
      "    \n",
      "    for i, (train_inx, test_inx) in enumerate(cv):\n",
      "        model = clf_pipe.fit(data_train[train_inx], y_train[train_inx])\n",
      "        pred = model.predict_proba(data_train[test_inx])\n",
      "        \n",
      "        fpr, tpr, thresh = metrics.roc_curve(y_train[test_inx], pred[:, 1])\n",
      "        auc_res += metrics.auc(fpr, tpr)\n",
      "        \n",
      "        tpr_interp += scipy.interp(xr, fpr, tpr)\n",
      "\n",
      "    print(\"Alpha = %.2f   ---->   AUC = %.4f\" %(param, auc_res/len(cv)))\n",
      "    \n",
      "    tpr_interp /= len(cv)\n",
      "    line_new = plt.plot(xr, tpr_interp)\n",
      "    plt.setp(line_new, color=col, linewidth=3, marker=ptype, markersize=8)\n",
      "    \n",
      "\n",
      "plt.setp(ax_roc.get_xticklabels(), rotation='horizontal', fontsize=16)\n",
      "plt.setp(ax_roc.get_yticklabels(), rotation='vertical', fontsize=16)\n",
      "plt.axis([-0.05, 1.05, -0.05, 1.05])\n",
      "plt.xlabel('False Positive Rate', size=20)\n",
      "plt.ylabel('True Positive Rate', size=20)\n",
      "plt.title('Multinomial NB Classification using TF-IDF Features', size=20)\n",
      "plt.legend(alpha_params, loc='lower right', fontsize=20)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "\n",
      "### Train a classifier object and test it on the test set:\n",
      "def apply_classifier(clf):\n",
      "    clf.fit(X_train, y_train)\n",
      "    pred = clf.predict(X_test)\n",
      "\n",
      "    #score = metrics.f1_score(y_train, pred)\n",
      "\n",
      "    return(pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
      "\n",
      "from timeit import timeit"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit pred_multNB = apply_classifier(MultinomialNB(alpha=.01))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10 loops, best of 3: 92.8 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred_multNB = apply_classifier(MultinomialNB(alpha=.01))\n",
      "\n",
      "pred_multNB = np.vstack((df_test.loc[:, 'id'], pred_multNB)).T\n",
      "\n",
      "pred_multNB.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "(25000, 2)"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.savetxt('../results/pred.multinomialNB.csv', pred_multNB, fmt='%s,%1d', delimiter=',', header='id,sentiment')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}