{
 "metadata": {
  "name": "",
  "signature": "sha256:49d12ceccec4fb9c4f3fcce7b71fe1725d62cbf45f8924a3111965846c0db3fc"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext watermark\n",
      "\n",
      "%watermark -a 'Vahid Mirjalili' -d -p scikit-learn,numpy,numexpr,pandas,matplotlib,plotly -v"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Vahid Mirjalili 17/12/2014 \n",
        "\n",
        "CPython 2.7.3\n",
        "IPython 2.3.1\n",
        "\n",
        "scikit-learn 0.15.2\n",
        "numpy 1.9.1\n",
        "numexpr 2.2.2\n",
        "pandas 0.15.1\n",
        "matplotlib 1.4.2\n",
        "plotly 1.4.7\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib import pyplot as plt\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import scipy\n",
      "import sklearn\n",
      "\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 1. Read the training dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_table('../data/labeledTrainData.tsv')\n",
      "\n",
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>id</th>\n",
        "      <th>sentiment</th>\n",
        "      <th>review</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 5814_8</td>\n",
        "      <td> 1</td>\n",
        "      <td> With all this stuff going down at the moment w...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 2381_9</td>\n",
        "      <td> 1</td>\n",
        "      <td> \\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 7759_3</td>\n",
        "      <td> 0</td>\n",
        "      <td> The film starts with a manager (Nicholas Bell)...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 3630_4</td>\n",
        "      <td> 0</td>\n",
        "      <td> It must be assumed that those who praised this...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 9495_8</td>\n",
        "      <td> 1</td>\n",
        "      <td> Superbly trashy and wondrously unpretentious 8...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "       id  sentiment                                             review\n",
        "0  5814_8          1  With all this stuff going down at the moment w...\n",
        "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
        "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
        "3  3630_4          0  It must be assumed that those who praised this...\n",
        "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 1.1 Extracting X & y data columns"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train = df.loc[:, 'review']\n",
      "\n",
      "y_train = df.loc[:, 'sentiment']\n",
      "\n",
      "X_train.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "0    With all this stuff going down at the moment w...\n",
        "1    \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
        "2    The film starts with a manager (Nicholas Bell)...\n",
        "3    It must be assumed that those who praised this...\n",
        "4    Superbly trashy and wondrously unpretentious 8...\n",
        "Name: review, dtype: object"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2. Text Feature Extraction"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "import string\n",
      "import re\n",
      "from collections import Counter\n",
      "\n",
      "from nltk.corpus import stopwords"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 2.1 Tokenizer Function"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      " **Transform to lower-case**  \n",
      " **Remove the punctuations**  \n",
      " **Remove the stopwrods**  \n",
      " **Tokenize the remaining string**  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## For more info, see http://www.cs.duke.edu/courses/spring14/compsci290/assignments/lab02.html\n",
      "\n",
      "stemmer = nltk.stem.porter.PorterStemmer()\n",
      "\n",
      "def get_tokens(inp_txt):\n",
      "    \n",
      "    ## Lower case: ABC -> abc\n",
      "    txt_lower = inp_txt.lower()\n",
      "  \n",
      "    ## Remove punctuations (!, ', \", ., :, ;, )\n",
      "    #txt_lower_nopunct = txt_lower.translate(string.maketrans(\"\",\"\"), string.punctuation)\n",
      "    #print(txt_lower_nopunct)\n",
      "    \n",
      "    \n",
      "    ## Tokenize:\n",
      "    tokens = nltk.word_tokenize(txt_lower) #_nopunct)\n",
      "    #tokens = nltk.wordpunct_tokenize(txt_lower)\n",
      "    \n",
      "    ## remove stop-words:\n",
      "    tokens_filtered = [w for w in tokens if not w in stopwords.words('english')]\n",
      "    \n",
      "    ## stemming:\n",
      "    stems = [stemmer.stem(t) for t in tokens_filtered]\n",
      "    stems_nopunct = [s for s in stems if re.match('^[a-zA-Z]+$', s) is not None]\n",
      "    return (stems_nopunct)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Unit test for tokenizer:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_tokens(\"What's in a name? That which we call a rose by any other name would smell as sweet.\")\n",
      "\n",
      "## Note: you need to download punkt package in nltk:\n",
      "# import nltk\n",
      "# nltk.download(punkt)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "[u'name', u'call', u'rose', u'name', u'would', u'smell', u'sweet']"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 2.2 TF-IDF Feature Extraction"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfidf = sklearn.feature_extraction.text.TfidfVectorizer(\n",
      "    encoding = 'utf-8',\n",
      "    decode_error = 'replace',\n",
      "    strip_accents = 'ascii',\n",
      "    analyzer = 'word',\n",
      "    smooth_idf = True,\n",
      "    tokenizer = get_tokens\n",
      ")\n",
      "\n",
      "tfidf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "TfidfVectorizer(analyzer='word', binary=False, charset=None,\n",
        "        charset_error=None, decode_error='replace',\n",
        "        dtype=<type 'numpy.int64'>, encoding='utf-8', input=u'content',\n",
        "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
        "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
        "        stop_words=None, strip_accents='ascii', sublinear_tf=False,\n",
        "        token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
        "        tokenizer=<function get_tokens at 0x8e53c80>, use_idf=True,\n",
        "        vocabulary=None)"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Unit test for TF-IDF:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Shakespear quote\n",
      "example_txt_1 = \"What's in a name? That which we call a rose by any other name would smell as sweet.\"\n",
      "example_txt_2 = \"To be, or not to be: that is the question.\"\n",
      "\n",
      "tfidf = tfidf.fit([example_txt_1 + example_txt_2])\n",
      "\n",
      "example1 = tfidf.transform([example_txt_1])\n",
      "example2 = tfidf.transform([example_txt_2])\n",
      "\n",
      "print('Features: %s' %tfidf.get_feature_names())\n",
      "print('Example1: %s' %example1.toarray())\n",
      "print('Example2: %s' %example2.toarray())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Features: [u'call', u'name', u'question', u'rose', u'smell', u'would']\n",
        "Example1: [[ 0.35355339  0.70710678  0.          0.35355339  0.35355339  0.35355339]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Example2: [[ 0.  0.  1.  0.  0.  0.]]\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 2.3 Evaluate TF-IDF on the reviews"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfidf = tfidf.fit(X_train.ravel())\n",
      "\n",
      "print('Feature-set size: %s' %len(tfidf.get_feature_names()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Feature-set size: 47448\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "\n",
      "pkl_out = open('tfidf_object.pkl', 'wb')\n",
      "pickle.dump(tfidf, pkl_out)\n",
      "pkl_out.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}